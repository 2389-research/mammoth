{"name":"pipeline_lifecycle","description":"Full pipeline lifecycle from DOT file to final outcome","given":"A DOT pipeline file with plan/implement/review nodes and goal_gate","when":"Parsed, validated, transformed, and executed through the real engine","then":"All nodes complete, artifacts written to disk, checkpoints saved, events emitted in correct order, context contains goal and outputs","validates":["parser","validator","transforms","engine","handlers","artifacts","checkpoints","events"]}
{"name":"http_server_lifecycle","description":"HTTP server submit/poll/stream/query end-to-end","given":"A PipelineServer with real engine and render functions","when":"Pipeline submitted via POST, status polled, SSE streamed, events queried/tailed/summarized, graph rendered","then":"All HTTP endpoints return correct status codes, valid JSON/SSE, proper filtering, and DOT graph output","validates":["server","sse_streaming","event_query","event_tail","event_summary","graph_rendering"]}
{"name":"checkpoint_resume","description":"Checkpoint save and resume with fidelity degradation","given":"A 5-node pipeline with full fidelity on one edge","when":"Executed to completion, checkpoint loaded from mid-pipeline, resumed from checkpoint","then":"Checkpoint files exist on disk, resume executes only post-checkpoint nodes, fidelity degrades to summary:high on first hop, final outcome matches fresh run","validates":["checkpoints","resume","fidelity_degradation","context_restoration"]}
{"name":"parallel_execution","description":"Parallel fan-out/fan-in with multiple join and error policies","given":"A pipeline with parallel fork, 3 branches, and fan-in node","when":"Executed with wait_all, wait_any, k_of_n, and fail_fast policies","then":"Branches execute concurrently, context merges correctly, branch isolation maintained, artifact manifests consolidated, failed branches handled per policy","validates":["parallel","fan_in","context_merge","branch_isolation","join_policies","error_policies","artifact_consolidation"]}
{"name":"human_gate_http","description":"Human-in-the-loop approve/reject flow via HTTP","given":"A pipeline with a human gate node served via HTTP","when":"Pipeline submitted, question polled, answer posted (approve or reject)","then":"Pipeline blocks at gate, question has correct prompt/options, answer unblocks execution, response stored in context, correct terminal node reached","validates":["human_gate","http_questions","http_answers","conditional_routing"]}
{"name":"error_recovery","description":"Retry, goal gate retry, loop restart, and conditional error routing","given":"Pipelines with failing nodes, retry policies, goal gates, and loop_restart edges","when":"Nodes fail with configurable patterns","then":"Retries execute correct number of times, goal gate triggers re-execution, loop restart creates fresh context, conditional edges route to error handlers, max limits enforced","validates":["retry","max_retry","goal_gate_retry","loop_restart","max_restarts","conditional_error_routing","retry_events","failure_events"]}
{"name":"dot_roundtrip","description":"DOT parse/serialize round-trip fidelity for all 12 example pipelines","given":"All 12 .dot files in examples/ directory","when":"Each file is parsed, serialized, re-parsed, and compared structurally; serialization checked for idempotency","then":"All files parse without error, re-parse produces structurally identical graph (same nodes, edges, attributes), serialization is idempotent","validates":["dot_parser","dot_serializer","round_trip_fidelity","idempotency","lint_warnings"]}
{"name":"web_project_lifecycle","description":"Web project CRUD, phase transitions, and persistence via HTTP and direct store","given":"A web.Server and web.ProjectStore with temp directory","when":"Projects created via HTTP POST, queried via JSON API, phases transitioned spec->edit->build->done, DOT and diagnostics updated, store reloaded","then":"HTTP endpoints return correct status codes and JSON, phase transitions persist correctly, list ordering is newest-first, store survives LoadAll reload with all state intact","validates":["web_server","project_store","http_api","phase_transitions","persistence","json_serialization"]}
{"name":"editor_session_lifecycle","description":"Editor session CRUD, DOT manipulation, undo/redo, and store management","given":"An editor.Store with sessions created from valid DOT","when":"Sessions created, DOT updated, nodes/edges added/removed/updated, undo/redo exercised, validation triggered, store cleanup and capacity eviction tested","then":"All graph mutations reflected in session state, undo restores previous state, redo re-applies, validation reports diagnostics for incomplete graphs, expired sessions cleaned up, capacity limits enforced","validates":["editor_store","editor_session","dot_manipulation","undo_redo","validation","cleanup","capacity_eviction"]}
{"name":"backend_wiring","description":"CodergenBackend construction, options, and interface compliance","given":"ClaudeCodeBackend and AgentBackend constructors with various configurations","when":"Backends constructed with API keys, functional options, missing binaries, cancelled contexts","then":"Both backends satisfy CodergenBackend interface, ClaudeCodeBackend accepts functional options (model, tools, budget, system prompt), missing binary fails gracefully, cancelled context propagates correctly, AgentBackend fails without API keys","validates":["claude_code_backend","agent_backend","functional_options","interface_compliance","error_handling","context_cancellation"]}
{"name":"subpipeline_composition","description":"Sub-pipeline graph composition with namespacing, reconnection, and nested inlining","given":"Parent and child DOT graphs with placeholder nodes marked for sub-pipeline insertion","when":"ComposeGraphs called with various configurations: single child, nested child-of-child, conflicting IDs, multiple sub-pipelines","then":"Placeholder removed, child nodes namespaced, edges reconnected to child start/terminal, attributes merged with parent precedence, nested composition double-namespaces, ID conflicts avoided, SubPipelineTransform loads from .dot files","validates":["compose_graphs","node_namespacing","edge_reconnection","attribute_merging","nested_composition","id_conflict_avoidance","sub_pipeline_transform","graph_integrity"]}
{"name":"edge_selection","description":"Edge selection algorithm with 5-tier priority and condition evaluation","given":"Graphs with edges using conditions, labels, suggested IDs, weights, and lexical ordering","when":"SelectEdge called with various outcomes, preferred labels, suggested IDs, and context values","then":"Condition evaluation routes correctly (=, !=, && conjunctions, context. prefix), preferred label matches with accelerator stripping, suggested IDs match in order, weight-based selection picks highest, lexical fallback breaks ties, NormalizeLabel handles all accelerator formats","validates":["condition_evaluation","preferred_label","suggested_ids","weight_selection","lexical_fallback","label_normalization","priority_cascade","context_conditions"]}
{"name":"dot_validator_exhaustive","description":"All 21 DOT validator lint rules with correct severity and diagnostics","given":"DOT graphs constructed to trigger each individual lint rule","when":"validator.Lint called on each graph","then":"Each rule fires with correct severity (error vs warning), correct rule name, and correct node/edge references in diagnostics; clean graph produces zero errors","validates":["start_node","exit_node","reachability","start_no_incoming","exit_no_outgoing","self_loop","dead_end","valid_shape","prompt_required","condition_syntax","max_retries","valid_weight","valid_fidelity","valid_rankdir","graph_goal","goal_gate_codergen","incomplete_outcomes","retry_target","edge_target_exists","type_known","goal_gate_has_retry"]}
{"name":"transform_chain_stylesheet","description":"Transform chain ordering and stylesheet specificity resolution","given":"Graphs with stylesheets using universal, class, and ID selectors plus variable references","when":"ApplyTransforms called with DefaultTransforms chain (SubPipeline, VarExpansion, Stylesheet)","then":"Specificity resolves correctly (universal < class < ID), variables expanded before stylesheet applied, node attrs override stylesheet, same-specificity last-rule-wins, invalid stylesheet silently skipped, transform ordering verified","validates":["stylesheet_specificity","variable_expansion","transform_ordering","node_attr_override","selector_matching","multi_class","default_transforms"]}
{"name":"spec_event_sourcing","description":"Spec persistence via JSONL event log with snapshot recovery","given":"A spec store with JSONL event log and snapshot files in temp directories","when":"Events written, spec recovered via full replay, snapshot created and loaded, incremental events replayed on snapshot, corrupted entries encountered","then":"Events persist as valid JSONL on disk, full replay produces equivalent state, snapshot recovery matches event replay, incremental events on snapshot produce correct state, corrupted entries skipped gracefully, three-way state equivalence verified","validates":["jsonl_event_log","full_replay","snapshot_creation","snapshot_recovery","incremental_replay","state_equivalence","corrupted_entries","repair_atomicity","large_event_sequences"]}
{"name":"interviewer_strategies","description":"All interviewer implementations in real pipeline execution","given":"Pipelines with human gate nodes using QueueInterviewer, RecordingInterviewer, AutoApproveInterviewer, and CallbackInterviewer","when":"Pipelines executed with each interviewer strategy, including single and multi-gate topologies","then":"Queue delivers answers in FIFO order with thread-safe access, Recording captures Q&A audit trail wrapping any inner interviewer, AutoApprove selects first option or explicit default, Callback receives correct question/options and supports dynamic decisions, all strategies integrate with real engine execution","validates":["queue_interviewer","recording_interviewer","auto_approve_interviewer","callback_interviewer","multi_gate_pipeline","context_propagation","event_verification","thread_safety"]}
{"name":"fidelity_transform","description":"Fidelity 4-tier precedence, all 6 modes, preamble injection, and checkpoint degradation","given":"Graphs with fidelity settings at edge, node, graph, and engine levels; contexts with various key patterns","when":"ResolveFidelity called with different precedence combinations, ApplyFidelity filters context per mode, GeneratePreamble creates mode descriptions, checkpoint resume degrades full to summary:high","then":"Edge > node > graph > engine precedence honored, full preserves all keys, compact removes internals, truncate limits key count, summary tiers progressively reduce, preamble injected for non-full modes, degradation only on full fidelity edges","validates":["fidelity_precedence","full_mode","compact_mode","truncate_mode","summary_high","summary_medium","summary_low","preamble_injection","checkpoint_degradation","generate_preamble"]}
{"name":"spec_export_formats","description":"Spec export to DOT, YAML, and Markdown with deterministic output","given":"A spec with cards across Ideas/Plan/Spec lanes including risk and constraint types","when":"ExportDOT, ExportYAML, and ExportMarkdown called on the same spec","then":"DOT contains digraph with metadata, start/exit nodes, excludes Ideas lane, includes risk and human gates; YAML preserves all cards with optional fields; Markdown has sections with lane ordering; all formats are deterministic across repeated calls","validates":["dot_export","yaml_export","markdown_export","determinism","lane_filtering","risk_gates","human_gates","card_metadata"]}
{"name":"watchdog_stall_detection","description":"Watchdog observation-only stall detection with single-warning semantics","given":"A Watchdog configured with short thresholds and multiple node tracking","when":"Nodes started, stalls detected, warnings emitted, restart and stop exercised, HandleEvent bridge tested, concurrent operations performed","then":"Stall warnings emitted after threshold, no cancellation (observation only), selective per-node stall detection, single warning per stall cycle, restart resets warning state, HandleEvent bridges engine events, concurrent operations race-free","validates":["stall_warning","observation_only","node_tracking","selective_stall","single_warning","restart_reset","handle_event_bridge","stall_metadata","concurrent_safety"]}
{"name":"artifact_collection","description":"ArtifactStore API, metadata, manifest tracking, and pipeline integration","given":"ArtifactStore instances with temp directories, real pipeline engine with artifact-producing handlers","when":"Artifacts stored/listed/retrieved/removed/cleared, metadata inspected, manifest tracked, pipeline nodes write artifacts via shared store","then":"Small artifacts in-memory, large artifacts file-backed, metadata timestamps and sizes accurate, manifest reflects operations, pipeline handlers share store, base dir matches engine config","validates":["artifact_store_api","file_backed_storage","metadata_accuracy","manifest_tracking","pipeline_integration","shared_store","base_dir_config"]}
{"name":"failure_signature_dedup","description":"Failure signature normalization for deterministic deduplication","given":"Error messages containing UUIDs, numbers, timestamps, file paths, hex addresses, and mixed variable content","when":"ComputeSignature normalizes variable content, FailureTracker records and counts signatures, concurrent access tested","then":"Same structure with different variables produces identical signatures, structurally different errors produce distinct signatures, signatures are stable across repeated computation, tracker deduplicates correctly, concurrent recording is thread-safe, edge cases (empty, whitespace, all-variable) handled","validates":["uuid_normalization","number_normalization","timestamp_normalization","path_normalization","hex_normalization","signature_stability","tracker_dedup","concurrent_safety","edge_cases"]}
{"name":"render_cache","description":"Render cache with TTL expiry, concurrent access, and SHA256 keying","given":"A RenderCache with configurable TTL","when":"Same input cached and retrieved, TTL expires, concurrent goroutines access cache, cache cleared, different inputs stored","then":"Cache hits return identical results, expired entries not returned, concurrent access race-free, clear empties all entries, SHA256 keys ensure input-sensitive cache separation","validates":["cache_hit","ttl_expiry","concurrent_access","cache_clear","sha256_keying","input_sensitivity"]}
{"name":"dot_fixer_llm","description":"DOT extraction from LLM output and real LLM-powered DOT fix","given":"Various LLM output formats (plain, markdown-fenced, mixed case, with explanations) and a broken DOT graph with validation errors","when":"extractDOTFromAgentOutput parses different formats, findMatchingBrace handles nested/quoted/escaped braces, real LLM fixes broken DOT via Cloudflare AI Gateway","then":"DOT extracted from all wrapper formats, error cases detected (no digraph, unterminated), brace matching handles nesting/quoting/escaping, LLM-fixed DOT has fewer validation errors than original","validates":["dot_extraction","markdown_fence_stripping","case_insensitive_parse","brace_matching","nested_braces","quoted_braces","escape_handling","llm_fix","validation_improvement"]}
{"name":"spec_import_llm","description":"LLM-powered spec import from freeform text with JSON extraction fallbacks","given":"Freeform project description text, various JSON wrapping formats (raw, markdown-fenced, prose-wrapped)","when":"ParseWithLLM extracts structured spec via real LLM call, ExtractJSON handles 3-tier fallback (raw JSON, code fences, brace matching), ToCommands generates CreateSpec/UpdateSpecCore/CreateCard commands","then":"LLM extracts title/goal/one_liner and cards with types, ExtractJSON handles all wrapper formats and rejects garbage, ToCommands produces correct command sequence with created_by:import on all cards","validates":["llm_extraction","freeform_parsing","json_tier1_raw","json_tier2_fenced","json_tier3_brace","garbage_rejection","command_generation","card_type_validation","created_by_tagging"]}
{"name":"spec_options_persistence","description":"Spec builder options parsing, constraint roundtrip, merge, and HTTP integration","given":"specBuilderOptions with HumanReview/ScenarioTesting/TDD toggles, constraint text with mammoth.option tags, web server with spec creation","when":"Options parsed from form values, serialized to constraint text, deserialized back, merged with existing constraints, applied via HTTP project creation","then":"Truthy values (1/true/yes/on/TRUE) parse correctly, falsy values (0/false/no/off/empty/other) parse correctly, roundtrip preserves all toggle states, merge replaces option lines without accumulation, hints included for enabled options, HTTP creation persists options in project constraints","validates":["truthy_parsing","falsy_parsing","constraint_roundtrip","merge_replace","hint_generation","http_integration","project_isolation"]}
